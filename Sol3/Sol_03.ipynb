{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 3 classes.\n",
      "generator\n",
      "Epoch 1/25\n",
      " 2/20 [==>...........................] - ETA: 0s - loss: 1.1324 - accuracy: 0.3571WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0370s vs `on_train_batch_end` time: 0.0730s). Check your callbacks.\n",
      "20/20 [==============================] - 28s 1s/step - loss: 1.1504 - accuracy: 0.3409\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 18s 893ms/step - loss: 1.0402 - accuracy: 0.4385\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 18s 887ms/step - loss: 0.9292 - accuracy: 0.5476\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 17s 849ms/step - loss: 0.7411 - accuracy: 0.6754\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 17s 836ms/step - loss: 0.5824 - accuracy: 0.7611\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 17s 857ms/step - loss: 0.4781 - accuracy: 0.8167\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 17s 862ms/step - loss: 0.3812 - accuracy: 0.8520\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 17s 859ms/step - loss: 0.2840 - accuracy: 0.9028\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 17s 874ms/step - loss: 0.2344 - accuracy: 0.9083\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 17s 870ms/step - loss: 0.2472 - accuracy: 0.9067\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 17s 874ms/step - loss: 0.1856 - accuracy: 0.9294\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 17s 868ms/step - loss: 0.1426 - accuracy: 0.9508\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 17s 856ms/step - loss: 0.1458 - accuracy: 0.9500\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 17s 845ms/step - loss: 0.1238 - accuracy: 0.9587\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 17s 874ms/step - loss: 0.1306 - accuracy: 0.9488\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 17s 870ms/step - loss: 0.0960 - accuracy: 0.9663\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 17s 851ms/step - loss: 0.1124 - accuracy: 0.9643\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 17s 860ms/step - loss: 0.1073 - accuracy: 0.9583\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 17s 864ms/step - loss: 0.0795 - accuracy: 0.9702\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 17s 855ms/step - loss: 0.0724 - accuracy: 0.9766\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 17s 857ms/step - loss: 0.0658 - accuracy: 0.9786\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 17s 852ms/step - loss: 0.0641 - accuracy: 0.9790\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 17s 845ms/step - loss: 0.0617 - accuracy: 0.9786\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 17s 849ms/step - loss: 0.1140 - accuracy: 0.9552\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 17s 858ms/step - loss: 0.0666 - accuracy: 0.9802\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score significantly\n",
    "# less than your Category 5 question.\n",
    "#\n",
    "# Don't use lambda layers in your model.\n",
    "# You do not need them to solve the question.\n",
    "# Lambda layers are not supported by the grading infrastructure.\n",
    "#\n",
    "# You must use the Submit and Test button to submit your model\n",
    "# at least once in this category before you finally submit your exam,\n",
    "# otherwise you will score zero for this category.\n",
    "# ======================================================================\n",
    "#\n",
    "# Computer Vision with CNNs\n",
    "#\n",
    "# Build a classifier for Rock-Paper-Scissors based on the rock_paper_scissors\n",
    "# TensorFlow dataset.\n",
    "#\n",
    "# IMPORTANT: Your final layer should be as shown. Do not change the\n",
    "# provided code, or the tests may fail\n",
    "#\n",
    "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
    "# So ensure that your input layer is designed accordingly, or the tests\n",
    "# may fail. \n",
    "#\n",
    "# NOTE THAT THIS IS UNLABELLED DATA. \n",
    "# You can use the ImageDataGenerator to automatically label it\n",
    "# and we have provided some starter code.\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def solution_model():\n",
    "#     url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
    "#     urllib.request.urlretrieve(url, 'rps.zip')\n",
    "#     local_zip = 'rps.zip'\n",
    "#     zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "#     zip_ref.extractall('tmp/')\n",
    "#     zip_ref.close()\n",
    "#     print('downloaded')\n",
    "\n",
    "    TRAINING_DIR = \"tmp/rps/\"\n",
    "    training_datagen = ImageDataGenerator(\n",
    "    # YOUR CODE HERE\n",
    "        rescale = 1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    train_generator = training_datagen.flow_from_directory( # YOUR CODE HERE\n",
    "        TRAINING_DIR,\n",
    "        target_size=(150, 150),\n",
    "        class_mode='categorical',\n",
    "        batch_size=126)\n",
    "    print('generator')\n",
    "    model = tf.keras.models.Sequential([\n",
    "    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The second convolution\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # The third convolution\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # The fourth convolution\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # Flatten the results to feed into a DNN\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # 512 neuron hidden layer\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(train_generator, epochs=25, steps_per_epoch=20, verbose = 1)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"mymodel.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cert (Python 3.7)",
   "language": "python",
   "name": "tf-cert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
